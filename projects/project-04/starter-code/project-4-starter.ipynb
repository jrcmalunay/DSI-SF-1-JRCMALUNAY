{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with stumbleupon data\n",
    "\n",
    "Project 4 has been changed since scraping was untenable. The project now focuses on the stumbleupon kaggle dataset. For more information on this dataset, [check out the website here](https://www.kaggle.com/c/stumbleupon).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the dataset\n",
    "\n",
    "This is the only part completed for you.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "su = pd.read_csv('../dataset/evergreen.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean up/examine your data\n",
    "\n",
    "Some of the columns may have values that need changing or that are of the wrong type. There could also be columns that aren't very useful.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "su['alchemy_category'] = su['alchemy_category'].apply(lambda x: 'unknown' if x == '?' else x)\n",
    "su['alchemy_category_score'] = su['alchemy_category_score'].apply(lambda x: 0 if x == '?' else float(x))\n",
    "su['is_news'] = su['is_news'].apply(lambda x: 0 if x == '?' else int(x))\n",
    "su['news_front_page'] = su['news_front_page'].apply(lambda x: 0 if x == '?' else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7390     computer_internet\n",
       "7391      culture_politics\n",
       "7392            recreation\n",
       "7393    arts_entertainment\n",
       "7394               unknown\n",
       "Name: alchemy_category, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "su.alchemy_category.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use statsmodels' logistic regression function to look at variable significance\n",
    "\n",
    "The **`import statsmodels.formula.api as smf`** code below gives us access to a statsmodels api that can run logistic regressions using patsy-style formulas.\n",
    "\n",
    "Ex:\n",
    "\n",
    "```python\n",
    "formula = 'target ~ var1 + var2 + C(var3) -1'\n",
    "logreg = smf.logit(formula, data=data)\n",
    "logreg_results = logreg.fit()\n",
    "print logreg_results.summary()\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Run a logistic regression predicting evergreen from the numeric columns\n",
    "\n",
    "And print out the results as shown in the example above.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# su.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.652585\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   No. Observations:                 7395\n",
      "Model:                          Logit   Df Residuals:                     7374\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 17 May 2016   Pseudo R-squ.:                 0.05804\n",
      "Time:                        10:33:51   Log-Likelihood:                -4825.9\n",
      "converged:                       True   LL-Null:                       -5123.2\n",
      "                                        LLR p-value:                3.821e-113\n",
      "==================================================================================================\n",
      "                                     coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "alchemy_category_score            -0.1598      0.078     -2.057      0.040        -0.312    -0.008\n",
      "avglinksize                        0.0015      0.003      0.525      0.599        -0.004     0.007\n",
      "commonlinkratio_1                  0.9664      0.211      4.581      0.000         0.553     1.380\n",
      "commonlinkratio_2                 -0.3552      0.374     -0.949      0.343        -1.089     0.378\n",
      "commonlinkratio_3                  3.2966      0.721      4.571      0.000         1.883     4.710\n",
      "commonlinkratio_4                 -2.0831      0.739     -2.818      0.005        -3.532    -0.634\n",
      "compression_ratio                 -0.0140      0.010     -1.436      0.151        -0.033     0.005\n",
      "embed_ratio                       -0.2357      0.177     -1.335      0.182        -0.582     0.110\n",
      "frameTagRatio                     -6.2620      0.783     -8.000      0.000        -7.796    -4.728\n",
      "hasDomainLink                      0.0020      0.167      0.012      0.991        -0.325     0.329\n",
      "html_ratio                         2.6012      0.351      7.416      0.000         1.914     3.289\n",
      "is_news                            0.1095      0.053      2.055      0.040         0.005     0.214\n",
      "image_ratio                       -0.0147      0.015     -0.996      0.319        -0.043     0.014\n",
      "lengthyLinkDomain                 -0.0501      0.061     -0.820      0.412        -0.170     0.070\n",
      "linkwordscore                     -0.0231      0.002    -13.906      0.000        -0.026    -0.020\n",
      "news_front_page                   -0.4781      0.133     -3.600      0.000        -0.738    -0.218\n",
      "non_markup_alphanum_characters -2.123e-05   3.85e-06     -5.507      0.000     -2.88e-05 -1.37e-05\n",
      "numberOfLinks                      0.0015      0.000      6.958      0.000         0.001     0.002\n",
      "numwords_in_url                   -0.0244      0.008     -2.955      0.003        -0.041    -0.008\n",
      "parametrizedLinkRatio              0.1884      0.135      1.399      0.162        -0.076     0.452\n",
      "spelling_errors_ratio             -1.1186      0.341     -3.283      0.001        -1.787    -0.451\n",
      "==================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import patsy\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula = 'label ~  alchemy_category_score + avglinksize + commonlinkratio_1 \\\n",
    "+ commonlinkratio_2 + commonlinkratio_3 + commonlinkratio_4 + compression_ratio + embed_ratio \\\n",
    "+ frameTagRatio + hasDomainLink+html_ratio + is_news + image_ratio + lengthyLinkDomain + linkwordscore\\\n",
    "+ news_front_page + non_markup_alphanum_characters + numberOfLinks \\\n",
    "+ numwords_in_url+parametrizedLinkRatio+spelling_errors_ratio + news_front_page -1'\n",
    "\n",
    "logreg = smf.logit(formula, data=su)\n",
    "logreg_results = logreg.fit()\n",
    "print logreg_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Run a logistic regression predicting evergreen from the numeric columns and a categorical variable of alchemy_category\n",
    "\n",
    "And print out the results as shown in the example.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.612383\n",
      "         Iterations 17\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   No. Observations:                 7395\n",
      "Model:                          Logit   Df Residuals:                     7361\n",
      "Method:                           MLE   Df Model:                           33\n",
      "Date:                Tue, 17 May 2016   Pseudo R-squ.:                  0.1161\n",
      "Time:                        10:33:52   Log-Likelihood:                -4528.6\n",
      "converged:                       True   LL-Null:                       -5123.2\n",
      "                                        LLR p-value:                1.136e-228\n",
      "===========================================================================================================\n",
      "                                              coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "C(alchemy_category)[arts_entertainment]     0.5673      0.225      2.524      0.012         0.127     1.008\n",
      "C(alchemy_category)[business]               1.9447      0.226      8.609      0.000         1.502     2.387\n",
      "C(alchemy_category)[computer_internet]      0.0849      0.263      0.323      0.746        -0.430     0.599\n",
      "C(alchemy_category)[culture_politics]       0.8858      0.239      3.709      0.000         0.418     1.354\n",
      "C(alchemy_category)[gaming]                 0.6040      0.320      1.887      0.059        -0.023     1.231\n",
      "C(alchemy_category)[health]                 1.3739      0.244      5.622      0.000         0.895     1.853\n",
      "C(alchemy_category)[law_crime]              1.0029      0.442      2.269      0.023         0.137     1.869\n",
      "C(alchemy_category)[recreation]             1.8371      0.217      8.470      0.000         1.412     2.262\n",
      "C(alchemy_category)[religion]               0.8753      0.327      2.680      0.007         0.235     1.515\n",
      "C(alchemy_category)[science_technology]     0.8457      0.248      3.408      0.001         0.359     1.332\n",
      "C(alchemy_category)[sports]                -0.2024      0.254     -0.798      0.425        -0.699     0.295\n",
      "C(alchemy_category)[unknown]                0.7817      0.195      4.018      0.000         0.400     1.163\n",
      "C(alchemy_category)[weather]              -44.9054    6.2e+09  -7.24e-09      1.000     -1.22e+10  1.22e+10\n",
      "alchemy_category_score                     -0.5307      0.157     -3.375      0.001        -0.839    -0.223\n",
      "avglinksize                                 0.0018      0.003      0.581      0.562        -0.004     0.008\n",
      "commonlinkratio_1                           0.6128      0.227      2.704      0.007         0.169     1.057\n",
      "commonlinkratio_2                          -0.2031      0.394     -0.516      0.606        -0.975     0.568\n",
      "commonlinkratio_3                           3.2416      0.740      4.382      0.000         1.792     4.691\n",
      "commonlinkratio_4                          -2.0256      0.757     -2.675      0.007        -3.509    -0.542\n",
      "compression_ratio                          -0.0085      0.010     -0.843      0.399        -0.028     0.011\n",
      "embed_ratio                                -0.1773      0.183     -0.968      0.333        -0.536     0.182\n",
      "frameTagRatio                              -6.4792      0.815     -7.946      0.000        -8.077    -4.881\n",
      "hasDomainLink                              -0.0876      0.172     -0.510      0.610        -0.424     0.249\n",
      "html_ratio                                  0.1664      0.609      0.273      0.784        -1.026     1.359\n",
      "is_news                                     0.1079      0.056      1.918      0.055        -0.002     0.218\n",
      "image_ratio                                -0.0242      0.016     -1.533      0.125        -0.055     0.007\n",
      "lengthyLinkDomain                          -0.0210      0.064     -0.330      0.741        -0.146     0.104\n",
      "linkwordscore                              -0.0237      0.002    -13.643      0.000        -0.027    -0.020\n",
      "news_front_page                            -0.6419      0.140     -4.573      0.000        -0.917    -0.367\n",
      "non_markup_alphanum_characters           -1.75e-05   3.89e-06     -4.499      0.000     -2.51e-05 -9.88e-06\n",
      "numberOfLinks                               0.0010      0.000      4.332      0.000         0.001     0.001\n",
      "numwords_in_url                            -0.0280      0.009     -3.210      0.001        -0.045    -0.011\n",
      "parametrizedLinkRatio                      -0.0491      0.146     -0.336      0.737        -0.335     0.237\n",
      "spelling_errors_ratio                      -1.2678      0.356     -3.558      0.000        -1.966    -0.569\n",
      "===========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import patsy\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula = 'label ~  C(alchemy_category) + alchemy_category_score + avglinksize + commonlinkratio_1 \\\n",
    "+ commonlinkratio_2 + commonlinkratio_3 + commonlinkratio_4 + compression_ratio + embed_ratio \\\n",
    "+ frameTagRatio + hasDomainLink+html_ratio + is_news + image_ratio + lengthyLinkDomain + linkwordscore\\\n",
    "+ news_front_page + non_markup_alphanum_characters + numberOfLinks \\\n",
    "+ numwords_in_url+parametrizedLinkRatio+spelling_errors_ratio + news_front_page -1'\n",
    "\n",
    "logreg = smf.logit(formula, data=su)\n",
    "logreg_results = logreg.fit()\n",
    "print logreg_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use sklearn to cross-validate the accuracy of the model above\n",
    "\n",
    "Normalize the numeric and categorical columns of the predictor matrix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>framebased</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>hasDomainLink</th>\n",
       "      <th>is_news</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>news_front_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>0</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  urlid  \\\n",
       "0  http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "\n",
       "                                         boilerplate  framebased  \\\n",
       "0  {\"title\":\"IBM Sees Holographic Calls Air Breat...           0   \n",
       "\n",
       "  alchemy_category  hasDomainLink  is_news  lengthyLinkDomain  news_front_page  \n",
       "0         business              0        1                  1                0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "su_cols = su[['url', 'urlid', 'boilerplate', 'framebased','alchemy_category','hasDomainLink',\\\n",
    "                'is_news','lengthyLinkDomain','news_front_page']]\n",
    "su_cols.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>embed_ratio</th>\n",
       "      <th>frameTagRatio</th>\n",
       "      <th>html_ratio</th>\n",
       "      <th>image_ratio</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.443783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090774</td>\n",
       "      <td>0.245831</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>24</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alchemy_category_score  avglinksize  commonlinkratio_1  commonlinkratio_2  \\\n",
       "0                0.789131     2.055556           0.676471           0.205882   \n",
       "\n",
       "   commonlinkratio_3  commonlinkratio_4  compression_ratio  embed_ratio  \\\n",
       "0           0.047059           0.023529           0.443783          0.0   \n",
       "\n",
       "   frameTagRatio  html_ratio  image_ratio  linkwordscore  \\\n",
       "0       0.090774    0.245831     0.003883             24   \n",
       "\n",
       "   non_markup_alphanum_characters  numberOfLinks  numwords_in_url  \\\n",
       "0                            5424            170                8   \n",
       "\n",
       "   parametrizedLinkRatio  spelling_errors_ratio  label  \n",
       "0               0.152941                0.07913      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "su_cols = su[[col for col in su if col not in su_cols]]\n",
    "su_cols.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "su_ = su_cols.ix[:,'alchemy_category_score':]\n",
    "# su.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ob = [c for c in su_.columns if c != 'label']\n",
    "\n",
    "su_.ix[:,ob] = (su_.ix[:,ob] - su_.ix[:,ob].mean())/su_.ix[:,ob].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "target = 'label'\n",
    "cols = [c for c in su_.columns if c != target]\n",
    "x = su_[cols]\n",
    "y = su_[target]\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.61621622  0.63218391  0.62407032  0.60987153  0.63193505]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model,x,y,cv=5)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LogisticRegression.score of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# su.head()\n",
    "model.fit(x,y)\n",
    "model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5176, 17) (5176,)\n",
      "(2219, 17) (2219,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.62280306444344302"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.30)\n",
    "print X_train.shape,Y_train.shape\n",
    "print X_test.shape, Y_test.shape\n",
    "tts = model.fit(X_train, Y_train)\n",
    "tts.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gridsearch regularization parameters for logistic regression\n",
    "\n",
    "Find the best regularization type (Ridge, Lasso) across a set of regularization strengths.\n",
    "\n",
    "[NOTE: C is the inverse of the regularization strength. Lower C values are stronger regularization. Having a C higher than 1 will significantly slow down the search. I'm not particularly interested in values over 1, since this is the default regularization strength in LogisticRegression.]\n",
    "\n",
    "**After you find the best set of parameters, build a Logistic Regression with those parameters and crossvalidate the score.**\n",
    "\n",
    "[NOTE 2: to run Lasso regularization the solver should be `'liblinear'`]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logistic = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'warm_start': [False, True], 'C': [0.01, 2.5], 'intercept_scaling': [2, 1], 'solver': ['liblinear'], 'fit_intercept': [False, True], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_parameters = {\n",
    "    \"penalty\":             ['l1','l2'],   # Used to specify the norm used in the penalization.\n",
    "    \"C\":                   [.01,2.5],  # Regularization paramter -- totally out of bounds but we will try it\n",
    "    #\"dual\":                [True, False], # Dual or primal formulation. Dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=False when n_samples > n_features\n",
    "    \"fit_intercept\":       [False, True], # Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.\n",
    "    #\"class_weight\":        [None, \"balanced\", \"auto\"], # The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))\n",
    "    \"intercept_scaling\":   [2, 1],        # Useful only if solver is liblinear. when self.fit_intercept is True, instance vector x becomes [x, self.intercept_scaling], i.e. a “synthetic” feature with constant value equals to intercept_scaling is appended to the instance vector. \n",
    "    \"solver\":              ['liblinear'],\n",
    "    \"warm_start\":          [False, True]\n",
    "}\n",
    "\n",
    "estimator = GridSearchCV(logistic, search_parameters)\n",
    "estimator.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'warm_start': [False, True], 'C': [0.01, 2.5], 'intercept_scaling': [2, 1], 'solver': ['liblinear'], 'fit_intercept': [False, True], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C / Regularization Param: 2.5\n",
      "Best Params: {'warm_start': False, 'C': 2.5, 'intercept_scaling': 2, 'solver': 'liblinear', 'fit_intercept': False, 'penalty': 'l2'}\n",
      "Best Score: 0.623738393218\n"
     ]
    }
   ],
   "source": [
    "print \"Best C / Regularization Param:\", estimator.best_estimator_.C # This estimator.best_estimator_ object has many great reporting metrics\n",
    "print \"Best Params:\", estimator.best_params_\n",
    "print \"Best Score:\", estimator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Evergreen       0.64      0.56      0.60      1198\n",
      "Non-Evergreen       0.62      0.69      0.65      1243\n",
      "\n",
      "  avg / total       0.63      0.63      0.63      2441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, estimator.predict(X_test)\n",
    "print classification_report(y_true, y_pred, target_names=[\"Evergreen\",\"Non-Evergreen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gridsearch neighbors for kNN\n",
    "\n",
    "Find the best number of neighbors with your predictors to predict the `label` target variable.\n",
    "\n",
    "Start by bulding a kNN model with a set number of neighbors, then use gridsearch to run through a series of neighbors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load gridsearch\n",
    "from sklearn import svm, grid_search, datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup our GridSearch Parmaters\n",
    "search_parameters = {\n",
    "    'n_neighbors':  [3,50], \n",
    "    'weights':      (\"uniform\", \"distance\"),\n",
    "    'algorithm':    (\"ball_tree\", \"kd_tree\", \"brute\", \"auto\"),\n",
    "    'p':            [1,2]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [3, 50], 'weights': ('uniform', 'distance'), 'algorithm': ('ball_tree', 'kd_tree', 'brute', 'auto'), 'p': [1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Intialize KNN \n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Intialize GridSearchCV\n",
    "clf = grid_search.GridSearchCV(knn, search_parameters)\n",
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [3, 50], 'weights': ('uniform', 'distance'), 'algorithm': ('ball_tree', 'kd_tree', 'brute', 'auto'), 'p': [1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Evergreen       0.69      0.52      0.59      1198\n",
      "Non-Evergreen       0.63      0.78      0.69      1243\n",
      "\n",
      "  avg / total       0.66      0.65      0.64      2441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print classification_report(y_true, y_pred, target_names=[\"Evergreen\",\"Non-Evergreen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Choose a new target from alchemy_category to predict with logistic regression\n",
    "\n",
    "**Ideally your category choice will have a small fraction of the total rows, but not TOO small!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Chose your target category, create the Y vector, and check the fraction of instances\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['business', 'recreation', 'health', 'sports', 'unknown',\n",
       "       'arts_entertainment', 'science_technology', 'gaming',\n",
       "       'culture_politics', 'computer_internet', 'law_crime', 'religion',\n",
       "       'weather'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "su.alchemy_category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new_target = su.alchemy_category[su.alchemy_category == 'recreation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    return 1 if x == \"recreation\" else 0\n",
    "\n",
    "## Copy of alchemy cat\n",
    "su['recreation'] = [x for x in su.alchemy_category.values]\n",
    "\n",
    "## Making it binary\n",
    "su['recreation'] = su.recreation.apply(step_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Use patsy to create an X matrix of the numeric predictors and all two-way interactions between them\n",
    "\n",
    "Ex:\n",
    "\n",
    "```python\n",
    "import patsy\n",
    "\n",
    "formula_interactions = '~ (var1 + var2 + var3)**2 -1'\n",
    "X_interactions = patsy.dmatrix(formula_interactions, data=data\n",
    "```\n",
    "\n",
    "Get the column names from the `design_info` property of the patsy X matrix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# C(alchemy_category) + alchemy_category_score + avglinksize + commonlinkratio_1 \\\n",
    "# + commonlinkratio_2 + commonlinkratio_3 + commonlinkratio_4 + compression_ratio + embed_ratio \\\n",
    "# + frameTagRatio + hasDomainLink+html_ratio + is_news + image_ratio + lengthyLinkDomain + linkwordscore\\\n",
    "# + news_front_page + non_markup_alphanum_characters + numberOfLinks \\\n",
    "# + numwords_in_url+parametrizedLinkRatio+spelling_errors_ratio + news_front_page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.464919\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             recreation   No. Observations:                 7395\n",
      "Model:                          Logit   Df Residuals:                     7385\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 17 May 2016   Pseudo R-squ.:                -0.03362\n",
      "Time:                        10:34:54   Log-Likelihood:                -3438.1\n",
      "converged:                       True   LL-Null:                       -3326.3\n",
      "                                        LLR p-value:                     1.000\n",
      "=========================================================================================================\n",
      "                                            coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "news_front_page                           0.3536      0.213      1.659      0.097        -0.064     0.771\n",
      "embed_ratio                               1.6033      0.242      6.625      0.000         1.129     2.078\n",
      "spelling_errors_ratio                   -16.0285      0.394    -40.679      0.000       -16.801   -15.256\n",
      "image_ratio                              -0.2064      0.045     -4.611      0.000        -0.294    -0.119\n",
      "news_front_page:embed_ratio               0.7260      0.799      0.909      0.363        -0.840     2.292\n",
      "news_front_page:spelling_errors_ratio     2.3825      1.617      1.473      0.141        -0.787     5.552\n",
      "news_front_page:image_ratio              -0.1548      0.252     -0.615      0.538        -0.648     0.338\n",
      "embed_ratio:spelling_errors_ratio       -17.0125      0.869    -19.579      0.000       -18.716   -15.309\n",
      "embed_ratio:image_ratio                  -0.9020      0.248     -3.634      0.000        -1.388    -0.416\n",
      "spelling_errors_ratio:image_ratio         1.2146      0.157      7.749      0.000         0.907     1.522\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import patsy\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula = 'recreation ~ (news_front_page + embed_ratio + spelling_errors_ratio +image_ratio)**2  -1'\n",
    "\n",
    "logreg = smf.logit(formula, data=su)\n",
    "logreg_results = logreg.fit()\n",
    "print logreg_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-cbb8762f3162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get the non-target cols with a simple list comprehension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnon_target_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msu_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnew_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Use some string adding and joining to make the simple model formula:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_target' is not defined"
     ]
    }
   ],
   "source": [
    "import patsy\n",
    "\n",
    "# Get the non-target cols with a simple list comprehension\n",
    "non_target_cols = [c for c in su_.columns if c != new_target]\n",
    "\n",
    "# Use some string adding and joining to make the simple model formula:\n",
    "formula_simple = target + ' ~ ' + ' + '.join(non_target_cols) + ' -1'\n",
    "print formula_simple\n",
    "\n",
    "# Make the complex formula:\n",
    "formula_complex = target + ' ~ (' + ' + '.join(non_target_cols) + ')**2 -1'\n",
    "print '\\n',formula_complex\n",
    "\n",
    "# Create the X and Y pairs for both!\n",
    "Y, X = patsy.dmatrices(formula_simple, data=su_)\n",
    "Yoverfit, Xoverfit = patsy.dmatrices(formula_complex, data=su_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Normalize the predictor matrix columns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Gridsearch a logistic regression to predict accuracy on your new target from the interaction predictors\n",
    "\n",
    "Include Ridge and Lasso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Build a logistic regression with the optimal parameters, and look at the coefficients\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Gridsearch parameters for a logistic regression with the same target and predictors, but score based on precision rather than accuracy\n",
    "\n",
    "Look at the documentation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [BONUS] 8. Build models predicting from words\n",
    "\n",
    "This is a bit of the NLP we covered in the pipeline lecture!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Choose 'body' or 'title' from the boilerplate to be the basis of your word predictors\n",
    "\n",
    "You will need to parse the json from the boilerplate field.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Use CountVectorizer to create your predictor matrix from the string column\n",
    "\n",
    "It is up to you what range of ngrams and features, and whether or not you want the columns binary or counts.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Gridsearch a logistic regression predicting accuracy of your chosen target category from word predictor matrix\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Do the same as above, but score the gridsearch based on precision rather than accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Build a logistic regression with optimal precision categories\n",
    "\n",
    "Print out the top 20 or 25 word features as ranked by their coefficients.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
